{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77a1981-6f63-4e99-884e-a0d900772e0d",
   "metadata": {},
   "source": [
    "# Assignment Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9f0d8-ea84-4a3a-bbfa-c87dfc5ae0b4",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7bf6fb-4457-4837-8d7e-eb5488beedff",
   "metadata": {},
   "source": [
    " Assumptions in ANOVA:<br>\n",
    "- Sampling distribution of mean should be normally distributed.\n",
    "- Outliers should not be present in the data.\n",
    "- There should be homogeneity in the variance of different levels population.\n",
    "- Each sample should be independent of each other and they should be selected at random.\n",
    "- For example, \n",
    "    - If the assumption of independence is violated, then the one-way ANOVA is simply not appropriate. \n",
    "    - If the assumption of normality is violated, or outliers are present, then the one-way ANOVA may not be the most powerful test available, and this could mean the difference between detecting a true difference among the population means or not.\n",
    "<br"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8767ec-eb67-489f-9079-1d38c8829b91",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dfdc5e-6d33-49c4-b637-a3a1fd46791e",
   "metadata": {},
   "source": [
    "There are three types of ANOVA as discussed below:<br><br>\n",
    "1. One-way ANOVA\n",
    "- It is used when there is only one factor.\n",
    "- There should be atleat 2 different levels.\n",
    "- Each level should be independent of each other.\n",
    "2. Repeated measure ANOVA\n",
    "- It is used when there is only one factor.\n",
    "- There should be atleat 2 different levels.\n",
    "- Each level may be dependent on each other.\n",
    "3. One-way ANOVA\n",
    "- It can be used when there is two or more factors.\n",
    "- There should be atleat 2 different levels.\n",
    "- Each level can be dependent or independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba656e8-e36f-49da-a816-c0a7835b3d77",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b17b30-22e7-4d74-b34c-9c35d2e30948",
   "metadata": {},
   "source": [
    "##### Part-1:<br><br>\n",
    "- An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the variance within a group. \n",
    "- This F-test betweent different groups is also came to be known as _Partitioning of variance in ANOVA_.\n",
    "##### Part-2:<br><br>\n",
    "- The F-test or partitioning of variance is very useful in decinding whether the mean of different groups are same or they are different.\n",
    "- That is, it helps us to perform the hypothesis testing, which we do finding the variance among and within the group variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de22a97-3dc6-4f50-a9e3-2f37eaf72502",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f6b5b-916c-4a34-b7ff-c9b7b1c03602",
   "metadata": {},
   "source": [
    "We can follow the steps given below to calculate SST, SSE and SSR in one-way ANOVA.<br><br>\n",
    "Step 1: First, we will calculate the mean for all three groups along with the grand (or “overall”) mean.<br><br>\n",
    "\n",
    "Step 2: Next, we will calculate the sum of squares regression (SSR) using the following formula:<br><br>\n",
    "\n",
    "nΣ(Xj – X..)2 <br><br>\n",
    "where:<br>\n",
    "\n",
    "n: the sample size of group j<br>\n",
    "Σ: a greek symbol that means “sum”<br>\n",
    "Xj: the mean of group j<br>\n",
    "X..: the overall mean<br><br>\n",
    "\n",
    "Step 3: Then, we will calculate the sum of squares error (SSE) using the following formula:<br><br>\n",
    "\n",
    "Σ(Xij – Xj)2<br><br> \n",
    "where:<br>\n",
    "Σ: a greek symbol that means “sum”<br>\n",
    "Xij: the ith observation in group j<br>\n",
    "Xj: the mean of group <br><br>\n",
    "\n",
    "Step 4: Finally, we will calculate the sum of squares total (SST) using the following formula:<br>\n",
    "SST = SSR + SSE<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b168283d-b383-4b12-abe8-ae34a400f3fd",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96578a07-d9b9-44e1-8798-3b8cc81136c5",
   "metadata": {},
   "source": [
    "- A main effect is the effect one independent variable has on the dependent variable without taking other independent variables into account. \n",
    "- An interaction is the effect one independent variable has on another independent variable, and how that effect translates to the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9089fe-b5ab-4770-8b02-fe1ebbfa1f71",
   "metadata": {},
   "source": [
    "So, to calculate main effects and interaction effects we can use the \"statsmodels\" library of python.<br><br>\n",
    "- Statsmodels library helps us to perform two-way anova test.\n",
    "- And the result of this test is a dataframe containing all the information related to main effect and interaction effect, which can be accessed directly using the key.\n",
    "<br><br>\n",
    "We can consider the example given below in order to understand, how can we calculate main effects and interaction effects data using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb0382-edbc-41ec-91b7-3c284600fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "  \n",
    "# Creating a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13, \n",
    "                                     14, 14, 14, 15, 16, 16, 17, 18,\n",
    "                                     14, 13, 14, 14, 14, 15]})\n",
    "  \n",
    "  \n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) +\\\n",
    "C(Fertilizer):C(Watering)',\n",
    "            data=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "  \n",
    "# Printing the result\n",
    "print(\"-------------------------------------Main effect of Fertilizer on height of plant -----------------------------------\")\n",
    "print(result.iloc[[0]],end=\"\\n\\n\\n\") # Main effect of Fertilizer on height\n",
    "print(\"-------------------------------------Main effect of Watering on height of plant -------------------------------------\")\n",
    "print(result.iloc[[1]],end=\"\\n\\n\\n\") # Main effect of Watering on height\n",
    "print(\"------------------------Interaction effect of both Fertilizer and Wateringon height of plant ------------------------\")\n",
    "print(result.iloc[[2]],end=\"\\n\\n\\n\") # Interaction effect of both Fertilizer and Watering on height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4a2ee-6988-46d6-8a05-37beae4fc9ca",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b267bce-9908-4a5f-a6f3-aaab71722f2b",
   "metadata": {},
   "source": [
    "At first, we will set a confidence level so that we can be calculate significance level value. The significance value help us to identify the extent to which the result is significant that null hypothesis can be rejected.<br><br>\n",
    "Let's take our confidence level to be 95%. Thus,<br>\n",
    "significance level = alpha =1-0.95<br>\n",
    "alpha = 0.05<br><br>\n",
    "Now, we will compare p-value with alpha to verify the null hypothesis.<br>\n",
    "And, if p value is less than alpha, then it simply means null hypothesis is not true.<br>\n",
    "Otherwise we can go with null hypothesis.<br><br>\n",
    "Here,<br>\n",
    "As, p < alpha i.e., 0.02 < 0.05, which means we need to reject the null hypothesis.<br><br>\n",
    "Hence,<br>\n",
    "we can conclude that there is a significant difference of mean in any of the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc87ee86-f0fa-49be-b03f-554a51b8bb80",
   "metadata": {},
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cef136-6378-425c-964f-306fe87d4fe6",
   "metadata": {},
   "source": [
    "##### Part-1:<br><br>\n",
    "- With repeated measures ANOVA, we can't use any of the data for that subject if the data is missing. \n",
    "- So, we need to use listwise deletion that is deletion from the entire row in case of missing data.\n",
    "- To perform a repeated measures ANOVA, all of the data must be eliminated from the data table.\n",
    "##### Part-2:<br><br>\n",
    "There are 2 primary ways of handling missing values:<br><br>\n",
    "1. Deleting the Missing values\n",
    "- This method deals with the missing value by deleting the entire row or column.\n",
    "- The disadvantage of this method is one might end up deleting some useful data from the dataset.\n",
    "- There are two ways one can delete the missing data values.\n",
    "     1. Deleting the entire row or listwise deletion\n",
    "     - If a row has many missing values, drop the entire row. \n",
    "     - If every row has some (column) value missing, then we might end up deleting the whole data.\n",
    "     2. Deleting the entire column\n",
    "     - In this process, whole column data is deleted if it has one or more missing values.\n",
    "2. Imputing the Missing Values\n",
    "- This method deals with the missing value by replacing the missing value with some other value using different techniques. \n",
    "- Some techiques to impute data are discussed below.\n",
    "     1. Replacing with the mean\n",
    "     - This is the most common method of imputing missing values of numeric columns. \n",
    "     - It is not suited for those types of data when there are outliers.\n",
    "     2. Replacing with an arbitrary value\n",
    "     - Here, we make guess to impute data.\n",
    "     - If the guess is incorrect then it can lead to false interpretation of the data due to presence of wrong value.\n",
    "     3. Replacing with the median\n",
    "     - It is one of the best method to handle missing data but it may not represent the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5d324-2a86-4405-8c54-906aeaec5a63",
   "metadata": {},
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddeec1-b021-4c78-aef8-110e51f88a8c",
   "metadata": {},
   "source": [
    "##### Part-1:<br><br>\n",
    "Some of the commonly used post-hoc tests after ANOVA are listed below:<br><br>\n",
    "1. Bonferroni Test.\n",
    "- This multiple-comparison post hoc correction is used when we are performing many independent or dependent statistical tests at the same time.<br>\n",
    "2. Tukey's Honest Significant Difference.\n",
    "- The purpose of Tukey’s test is to figure out which groups in your sample differ. \n",
    "- It uses the “Honest Significant Difference,” a number that represents the distance between groups, to compare every mean with every other mean.<br>\n",
    "3. Scheffe's Test\n",
    "- It is used when we want to look at post hoc comparisons in general (as opposed to just pairwise comparisons). \n",
    "- It controls for the overall confidence level. \n",
    "- It is customarily used with unequal sample sizes.<br>\n",
    "##### Part-2:<br><br>\n",
    "- Post hoc tests are only used in conjunction with tests of group difference, such as ANOVA, and are only necessary when the independent variable (sometimes called a “factor”) possesses three or more groups.\n",
    "- When there is a statistically significant difference between the group means overall, post hoc tests are used to determine where the differences between groups actually happened. (i.e., a statistically significant one-way ANOVA result). \n",
    "- The experiment-wise error rate is attempted to be regulated by post hoc analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0f8fb-faab-4a07-8f13-a080b306df2b",
   "metadata": {},
   "source": [
    "# 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ca711-e4fd-4770-af96-a5b1fb4da6c8",
   "metadata": {},
   "source": [
    "- Let's take the significance level to be 0.05<br>\n",
    "- Hypothesis<br>\n",
    "H<sub>0</sub> : mu1 = mu2 = mu3<br>\n",
    "H<sub>1</sub> : Any of the mean is not equal.<br><br>\n",
    "- Generating random numbers and weights for each group.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969d49d-700d-4bcf-b343-10308ae84481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6ecbff-dfb3-4f27-a715-163891f0fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 3 random numbers which represent no. of person for each diet group\n",
    "def sample(nof_samples, min_n, max_n, sum_n):\n",
    "    p = np.full(nof_samples, 1.0/np.float64(nof_samples)) # probabilities\n",
    "\n",
    "    while True:\n",
    "        q = np.random.multinomial(sum_n, p)\n",
    "        if not np.any(q > max_n):\n",
    "            if not np.any(q < min_n):\n",
    "                return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653008e0-a41c-440d-98fb-a0010e4447a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people in 3 diet groups\n",
    "groups = sample(3, 10, 17, 50)\n",
    "# Weight distribution for group A\n",
    "groupA = np.random.randint(30,90,groups[0]) \n",
    "# Weight distribution for group B\n",
    "groupB = np.random.randint(30,90,groups[1]) \n",
    "# Weight distribution for group C\n",
    "groupC = np.random.randint(30,90,groups[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b91c8a-aa96-4da4-acbc-17721eb4cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conducting the one-way ANOVA\n",
    "f_stat, p = f_oneway(groupA, groupB,groupC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0489d-420d-4062-87f6-706a751a51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "print(f\"F-statistics: {f_stat:.3f}\")\n",
    "print(f\"P-value: {p:.3f}\")\n",
    "\n",
    "# Making Decision\n",
    "if(p<0.05):\n",
    "    print(\"There is a significant difference in mean weight loss of at least one of the groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in mean weight loss of groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8974851-1c99-4a55-a0a4-18ccf92e5f1c",
   "metadata": {},
   "source": [
    "# 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb78e59-c287-4463-91ea-1a4151a2f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332a22f-a853-4fc1-b6b4-fac74285110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate 3 random numbers which represent no. of employee for each program group.\n",
    "def sample(nof_samples, min_n, max_n, sum_n):\n",
    "    p = np.full(nof_samples, 1.0/np.float64(nof_samples)) # probabilities\n",
    "\n",
    "    while True:\n",
    "        q = np.random.multinomial(sum_n, p)\n",
    "        if not np.any(q > max_n):\n",
    "            if not np.any(q < min_n):\n",
    "                return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79ab79-324b-4b74-92fe-94da47da9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining programs as a numerical value\n",
    "programs ={\n",
    "    0:\"Program A\",\n",
    "    1:\"Program B\",\n",
    "    2:\"Program C\"\n",
    "}\n",
    "# Randomly Distributing program to each of 30 employee\n",
    "programs_num = np.random.randint(0,3,30)\n",
    "programs_categorical = np.array([programs[i] for i in programs_num])\n",
    "\n",
    "# Randomly Distributing time taken by each employee in minutes\n",
    "time = np.random.randint(1,60,30)\n",
    "\n",
    "# Employee experience level distribution for where 0-novice and 1-experienced\n",
    "employeeExp = [ round(i) for i in np.random.rand(30)]\n",
    "\n",
    "# Creating Dataframe\n",
    "dataframe = pd.DataFrame({\n",
    "                \"programs\":programs_categorical,\n",
    "                \"employeeExp\":employeeExp,\n",
    "                \"time\" : time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484db38-5162-4dcc-97d7-1824d5c619e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing two-way ANOVA\n",
    "model = ols('time ~ C(programs_categorical) + C(employeeExp) + C(programs_categorical):C(employeeExp)',\n",
    "            data=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "  \n",
    "# Printing the result\n",
    "print(\"-----------------------------------------Main effect of Programs on time ----------------------------------------\")\n",
    "print(result.iloc[[0]],end=\"\\n\\n\\n\") # Main effect of Programs on time\n",
    "print(f\"F-value : {result.iloc[[0]]['F']}\",end=\"\\n\\n\\n\") # F-value for Main effect of Programs on time\n",
    "print(f\"P-value : {result.iloc[[0]]['PR(>F)']}\",end=\"\\n\\n\\n\") # P-value for Main effect of Programs on time\n",
    "print(\"-----------------------------------------Main effect of Employees on time ----------------------------------------\")\n",
    "print(result.iloc[[1]],end=\"\\n\\n\\n\") # Main effect of Employees on time\n",
    "print(f\"F-value : {result.iloc[[1]]['F']}\",end=\"\\n\\n\\n\") # F-value for Main effect of Employees on time\n",
    "print(f\"P-value : {result.iloc[[1]]['PR(>F)']}\",end=\"\\n\\n\\n\") # P-value for Main effect of Employees on time\n",
    "print(\"------------------------Interaction effect of both Programs and Employees height of plant ------------------------\")\n",
    "print(result.iloc[[2]],end=\"\\n\\n\\n\") # Interaction effect of both Programs and Employees height of plant\n",
    "print(f\"F-value : {result.iloc[[2]]['F']}\",end=\"\\n\\n\\n\") # F-value for Interaction effect of both Programs and Employees height of plant\n",
    "print(f\"P-value : {result.iloc[[2]]['PR(>F)']}\",end=\"\\n\\n\\n\") # P-value for Interaction effect of both Programs and Employees height of plant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773fdb2-3ec5-4f29-937c-0269b25b2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Decisions\n",
    "interaction_bool = result.iloc[[2]]['PR(>F)']<0.05\n",
    "programs_bool = result.iloc[[0]]['PR(>F)']>0.05\n",
    "employeeExp_bool = result.iloc[[1]]['PR(>F)']>0.05\n",
    "\n",
    "if(interaction_bool[[0]][0]):\n",
    "    print(\"Any one of the two factors i.e., either programs or employees experience level is having effect on time\")\n",
    "else:\n",
    "    if(programs_bool[[0]][0]):\n",
    "        print(\"Programs effect the time of execution\")\n",
    "    else:\n",
    "        print(\"Programs does not effect the time of execution\")\n",
    "    if(employeeExp_bool[[0]][0]):\n",
    "        print(\"Employees experience effect the time of execution\")\n",
    "    else:\n",
    "        print(\"Employees experience does not effect the time of execution\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4eacb6-75b4-4966-b7d7-8a68cbb5cc03",
   "metadata": {},
   "source": [
    "# 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4054e1f-6362-422d-8e5d-af869eb46503",
   "metadata": {},
   "source": [
    "- Let's take the significance level to be 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43efed-20db-496d-90a9-8da955b4c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing posthocs library\n",
    "!pip install scikit-posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74734a7-68c8-4922-acdb-dc901aabd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import scipy.stats as stat\n",
    "import scikit_posthocs as sp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd151a-8322-481e-b3c3-3946bf2b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marks distribution for students using traditional teaching method\n",
    "groupA = np.random.randint(0,100,50) \n",
    "# Marks distribution for students using new teaching method\n",
    "groupB = np.random.randint(0,100,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a25068-0ac9-4e53-9912-5519444d633a",
   "metadata": {},
   "source": [
    "- Before conducting the two-sample T-Test we need to find if the given data groups have the same variance. If the ratio of the larger data groups to the small data group is less than 4:1 then we can consider that the given data groups have equal variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367d924-2b5d-44f8-93f0-e10b20ceac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Equal variance boolean\n",
    "equal_var = True\n",
    "# Finding min and max variances among groups \n",
    "var_mx = max(np.var(groupA), np.var(groupB))\n",
    "var_mn = min(np.var(groupA), np.var(groupB))\n",
    "\n",
    "if(var_mx/var_mn < 4):\n",
    "    equal_var = True\n",
    "    print(\"Given data group have equal variances\")\n",
    "else:\n",
    "    equal_var = False\n",
    "    print(\"Given data group have different variances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391104c-88b5-4e82-b8aa-ae739bd5f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the two sample t-test \n",
    "t_stat, p = stat.ttest_ind(a=groupA, b=groupB, equal_var=equal_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebe05e-6dd0-439a-a55e-768e4e86e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Results\n",
    "print(f\"T-statistics: {t_stat:.3f}\")\n",
    "print(f\"P value: {p:.3f}\")\n",
    "\n",
    "# Making Decisions\n",
    "isSignificantDiff = False\n",
    "if(p<0.05):\n",
    "    isSignificantDiff = True\n",
    "    print(\"There is a significant difference in test scores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e80ae-bcd3-4740-a127-7938add85db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing parameteric Post-hoc test\n",
    "if(isSignificantDiff):\n",
    "    x=sp.posthoc_ttest(pd.DataFrame({\"groups\":[\"groupA\"]*50+[\"groupB\"]*50,\"score\":np.concatenate((groupA,groupB))}),val_col='score', group_col='groups')\n",
    "    print(\"--------------------------------Post-hoc test result--------------------------------\\n\\n\")\n",
    "    print(x)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9da578-4f27-4dbb-8ea7-7222700cdbe1",
   "metadata": {},
   "source": [
    "# 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e506ee-f668-45f9-9019-bd8d4e3f9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dfd82-b7ec-461c-8022-85d1597107ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sales record for store A\n",
    "storeA = np.random.randint(0,200,30) \n",
    "# Random sales record for store B\n",
    "storeB = np.random.randint(0,200,30) \n",
    "# Random sales record for store C\n",
    "storeC = np.random.randint(0,200,30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f62c6b-abbb-47c7-95dd-8d4661ffcebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "dataframe = pd.DataFrame({'stores': np.array([\"storeA\"]*30+[\"storeB\"]*30+[\"storeC\"]*30),\n",
    "                          'days': np.tile(list(range(1,31)), 3),\n",
    "                          'sales': np.concatenate((storeA,storeB,storeC))})\n",
    "  \n",
    "# Conducting the repeated measures ANOVA\n",
    "repeatedMeasure_ANOVA = AnovaRM(data=dataframe, depvar='sales',subject='days', within=['stores']).fit()\n",
    "\n",
    "\n",
    "# Printing Results\n",
    "print(\"-------------------------------Results Of Repeated Measure ANOVA----------------------------------\\n\\n\")\n",
    "print(repeatedMeasure_ANOVA )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbdc1b-6217-41d4-9acd-108a350a1059",
   "metadata": {},
   "source": [
    "From the above repeated measure anova result, we will capyure the p-value, which in this case is,<br>\n",
    "p = 0.1979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4504068-7443-44d6-9d35-fe8ae7742867",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1979\n",
    "print(f\"P value: {p:.3f}\")\n",
    "\n",
    "# Making Decisions\n",
    "isSignificantDiff = False\n",
    "if(p<0.05):\n",
    "    isSignificantDiff = True\n",
    "    print(\"There is a significant difference in test scores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b1b97-50f2-4ca6-8102-f5f2002fa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Tukey's Honest Significant Difference Post-hoc test\n",
    "if(isSignificantDiff):\n",
    "    sales = [storeA, storeB, storeC]\n",
    "    stores = [['storeA'] * 30, ['storeB'] * 30, ['storeC'] * 30]\n",
    "    res = sp.posthoc_tukey_hsd(np.concatenate(sales), np.concatenate(stores))\n",
    "    print(\"--------------------------------Post-hoc test result--------------------------------\\n\\n\")\n",
    "    print(res)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e68b44-38b6-483c-99d7-722bbd91bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
