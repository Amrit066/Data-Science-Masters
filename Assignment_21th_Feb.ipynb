{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce37888e-a8f8-46a0-a1fd-c3c3d22506f8",
   "metadata": {},
   "source": [
    "# Assignment Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ff63f-4bc0-479b-b853-c8b29a64a740",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bbe1b-704f-4e61-9353-aa04bef5589d",
   "metadata": {},
   "source": [
    "##### Part-1:<br><br>\n",
    "- The method for gathering information and data from the internet is called web scraping. \n",
    "- This data is usually saved in to a file so that it can be used for future manipulation or obtaining insights from it.\n",
    "<br><br>\n",
    "##### Part-2:<br><br>\n",
    "- It can be used to collect and analyze data related to a specific category from multiple websites.\n",
    "- It can be used to periodically extract data of products from various e-commerce websites.\n",
    "- It can be used to generate leads for marketing.\n",
    "<br><br>\n",
    "##### Part-3: The three areas where web scrapping is used are;<br><br>\n",
    "- To monitor prices of products on e-commerce websites.\n",
    "- To analyze data produce from social medias.\n",
    "- To analyze prices of stock for effective investment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5977d5-7969-49b1-8adc-9134cc91a0ab",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06682a-8270-47f2-958c-5783d232e7c1",
   "metadata": {},
   "source": [
    "The different methods used for web scrapping are:<br>\n",
    "- Manually copying and pasting data from a web page into a text file or spreadsheet is the most basic form of web scraping.\n",
    "- Information can be extracted from web pages using the regular expression-matching features of computer languages or the UNIX grep utility.\n",
    "- HTML parsing technique can be used to collect data as many websites contain large collections of pages.\n",
    "- In order to recognize and extract information from websites by visually reading pages as a human would, there are attempts to employ machine learning and computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782704ac-a6ea-40a7-9809-c1abf8190af5",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af42e5a-f8f3-455c-9442-3ddf72a70675",
   "metadata": {},
   "source": [
    "##### Part-1:<br><br>\n",
    "- It is a pyhton package that is used to extract data from markup languages like HTML, XML, and others.\n",
    " \n",
    "- It is a web scraping program that assists you in cleaning up and parsing the documents you have downloaded from the internet.\n",
    "<br><br>\n",
    "##### Part-2:<br><br>\n",
    "- It is basically used to get the data of interest from the web pages.\n",
    "- - With the use of Beautiful Soup, We can extract specific information from a webpage by completely remove the HTML syntax, and save the data.\n",
    "- It converts the structure of a web page into a form which can be utilized to get the information from its hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a1182-0730-48ad-9837-d5fd844d73e3",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6e2d9-a9b0-4c85-8b8a-5a7c6449db06",
   "metadata": {},
   "source": [
    "- Flask is used in this web scraping project because it is a is a lightweight framework to build websites.\n",
    "- It provides us simple tools to build APIs, which can be used to route from one pages to other as it has been done in the project i.e., when users are clicking search button after giving the search text, then they are directed to other page where everything is being shown in formatted manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0fc16-6556-42da-a736-b06643fc4d5f",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc931c-b701-4f5d-b177-f8a3103676a2",
   "metadata": {},
   "source": [
    "1. CodePipeleine<br><br>\n",
    "- It is a continuous delivery service that enables us to model, visualize, and automate the steps required to release the software. \n",
    "- We can model the entire release process for developing our code, deploying it to test environments, testing your application, and releasing it to production using AWS CodePipeline.\n",
    "- It builds, tests, and deploys our application according to the defined workflow every time there is a code change.\n",
    "<br><br>\n",
    "2. Beanstalk<br><br>\n",
    "- It is a platform within AWS that is used for deploying and scaling web applications.\n",
    "- It takes our application code and deploys it while provisioning the supporting architecture and compute resources required for our code to run.\n",
    "- It also fully manages the patching and security updates for those provisioned resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad6cdb-69c7-43ec-b18c-f8d50e19e877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
